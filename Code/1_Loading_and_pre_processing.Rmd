---
title: "1_loading_and_pre_processing"
author: "Pedro Beschoren da Costa"
date: "August 24, 2021"
output: html_document
editor_options: 
  chunk_output_type: console
---
## 0 - Loading  R Libraries

```{r load_install_packages}

#Set working directory to project directory 
setwd("./")
getwd() #ok

# Load required packages
#library("devtools")  # needed to install some packages
#library("BiocManager")  # needed to install some packages
#library("remotes")  # needed to install some packages
#library("Boruta")  # for random forest feature selection
#library("mlbench")  # for random forest
#library("caret")  # for random forest
#library("randomForest")  # for random forest


#Handling data 
library("dplyr")
library("tibble")
library("stringr")  # to wrangle string vectors
library("tidyr")
library("ggrepel")  # to avoid legends overlapping in your plot
library("ggpubr")
library("purrr")  # has map() to select table elements

#Microbiome
library("vegan")  # for several essential statistical tests
library("forcats")
library("metagMisc")  # lets you create lists of split phyloseq objects
library("phyloseq")
library("decontam")
library("metagenomeSeq")
library("Biostrings")

#Visuals
library("ggplot2")
#library("igraph")  # calculates network metrics and manipulates network objects
# library("WGCNA")  # needed for eigen_correlation(), allowing you to correlate metadata to network modules
#library("pheatmap")  # heatmaps for DESeq2
#library("viridis")  # nice colors
#library("metacoder")  # plots heat trees

#stats
library("agricolae")  # includes some ANOVA post-hoc options
library("minpack.lm")  # lets you do some HSD tests, output is a nice table
#library("Hmisc")  # for neutral models
#library("spaa")  # need to install Ecoutils
#library("stats4")  # for neutral models
library("car")  # for Levene's test
#library("indicspecies")  # runs indicator species analysis

```


## 1 - Loading data 
our data (processed in qiime2) was saved in BIOM format, making importing easier since there are less files to handle


```{r results="hide"}
##### Loading Microbiome data ##########

# This will load all the essential data (OTU frequencies, representative sequences, mapping files with metadata, taxonomy) for a single phyloseq object
physeq <- import_biom("./Data/Pilot_phyloseq_input_FeatureTable_metadata_taxonomy.biom",
  refseqfilename = "./Data/dna-sequences.fasta"
)

# let's check the imported objects. Often errors will arise from typos when filling up the data sheets
head(otu_table(physeq))
head(sample_data(physeq))
head(tax_table(physeq))

# note that dada2 will give us horrible OTU names, let's change this with a custom function
source("./Code/Functions/backup_and_rename.R") # source will load the function inside the Code folder of this R project

# this will run the custom function and update the phyloseq object
physeq <- backup_and_rename(physeq) # this function runs slow inside the chuck but fast on the console.... to solve this, click on the gear icon just next to the knit button and set "chuck output in the console" instead of "chunk output inline"
```


### 1.1 Decontamination process

```{r}
# Before we proceed, let's prepere phyloseq object for decontamination using the decontam package
physeq_norm <- transform_sample_counts(physeq, function(OTU) OTU / sum(OTU)) # transforms to relative frequency
colSums(otu_table(physeq_norm)) # checks if sums are 1
sample_data(physeq_norm)$is.neg <- sample_data(physeq_norm)$Plant_species == "Blank" # set negatives as TRUE in a  new column

# decontaminate! read details on decontam package. grouping your blanks in batches (such as sampling blanks, DNA extraction blanks, PCR blanks) can help you remove contaminants according different sources. Try to obtain the DNA concentration from the PCR product to include this variable in the decontamination process.
decontam_output <- isContaminant(physeq_norm,
  neg = "is.neg",
  threshold = 0.1
) # using 0.1  gave us only one single contaminant
table(decontam_output$contaminant) # this shows the number of  contaminates (=TRUE)
head(decontam_output) # checks decontam output

contaminants <- rownames(subset(decontam_output, contaminant %in% c("TRUE")))
contaminants # this is a list of otus classified as contaminants


# Make phyloseq object of presence-absence (pa) in negative controls and true samples
physeq_norm_pa <- transform_sample_counts(physeq_norm, function(abund) 1 * (abund > 0))
physeq_norm_pa_neg <- prune_samples(
  sample_data(physeq_norm_pa)$Plant_species == "Blank",
  physeq_norm_pa
)
physeq_norm_pa_pos <- prune_samples(
  sample_data(physeq_norm_pa)$Plant_species != "Blank",
  physeq_norm_pa
)

# Make data.frame of prevalence in positive and negative samples
physeq_norm_df_pa <- data.frame(
  pa.pos = taxa_sums(physeq_norm_pa_pos),
  pa.neg = taxa_sums(physeq_norm_pa_neg),
  contaminant = decontam_output$contaminant
)

ggplot(data = physeq_norm_df_pa, aes(x = pa.neg, y = pa.pos, color = contaminant)) +
  geom_point() +
  xlab("Prevalence (Negative Controls)") +
  ylab("Prevalence (True Samples)")

# clean physeq object by removing contaminant OTUS, then remove blank sample
physeq_decontaminated <- prune_taxa(!taxa_names(physeq) %in% contaminants, physeq) # keep only taxa that are not in the list of contaminants
physeq_decontaminated <- subset_samples(physeq_decontaminated, colSums(otu_table(physeq_decontaminated)) > 0)

# clean physeq object by removing blank samples
physeq_decontaminated <- subset_samples(physeq_decontaminated, Plant_species != "Blank")

# now that we finished decontamination, let's remove unecessary objects and liberate some memory
rm(physeq_norm_df_pa, physeq_norm_pa_pos, physeq_norm_pa, physeq_norm)
gc()
```
Decontamination with the decontam package only removed a single OTU from analysis. 

### 1.2 Chloroplast and mitochondrial DNA removal
Chloroplast and mitochondria DNA can be amplified by 16s primers that target bacteria. there are many approaches to reduce this problem, such as PCR blockers called PNA clamps. sometimes this is simply not enough, depending on bacterial populations and plastid DNA. A good sequencing of leaf bacterial communities can be extremely challenging due to this problem 

Here, we remove this plant sequences according the taxonomy given to the ASV by the taxa classifier in qiime2. On this chunk we will not perform any in-depht analysis or calculation.


```{r}

# First, a quick check to detect the presence of  o__Chloroplast or f__Mitochondria
plot_bar(subset_taxa(physeq_decontaminated, Order == "o__Chloroplast"), facet_grid = ~Sample_type) # this shows we do have some plastid DNA arround
plot_bar(subset_taxa(physeq_decontaminated, Family == "f__Mitochondria"), facet_grid = ~Sample_type) # this shows we do have some mitochndrial DNA arround


# load and run  the fucntion that will remove the plant DNA. press F2 after selecting the custom function to open it on a new tab
source("./Code/Functions/remove_Chloroplast_Mitochondria.R")
physeq_clean <- remove_Chloroplast_Mitochondria(physeq_decontaminated)

# This will check if you still have those taxa in your phyloseq object. if the output is FALSE, then you got rid of them
"o__Chloroplast" %in% tax_table(physeq_clean)
"f__Mitochondria" %in% tax_table(physeq_clean)
```

Now your bacterial phyloseq object is rid of detectable contaminants and plant DNA. note that for fungal ITS sequences you may  have some plant or microfauna DNA in the middle of your fungal sequences!




### 1.3 Filtering out rare ASVs
now that our sequences are free of contaminants and plant DNA, let's remove reads that are much too rare. Here we will use the UNOISE3 standard of removing ASVs that occur less than 8 times (https://drive5.com/usearch/manual/cmd_unoise3.html)


```{r echo=TRUE, fig.show=hold}
# to be valid, an ASV may not be a singleton
physeq_filtered <- physeq_clean # ... but first let's save the non-filtered phyloseq object in separate
otu_table(physeq_filtered) <- otu_table(physeq_filtered)[which(rowSums(otu_table(physeq_filtered)) > 8), ] # this drops ~3000 taxa.

# let's see how many sequences were kept after this filtering
sum(sample_sums(physeq_filtered)) / sum(sample_sums(physeq_clean)) * 100

# we kept 99.48% of sequences. let's now compare the histograms
ggplot() +
  geom_density(aes(x = sample_sums(physeq_filtered)), fill = 3, alpha = 0.5) +
  geom_density(aes(x = sample_sums(physeq_clean)), fill = 1, alpha = 0.5)


```


### 1.4 Data Normalization


A big challenge in microbiome data is the difference in library sizes: some samples are covered more in depth than others. this means sample1 may have 12.000 sequences, while samples2 may have 150.000 sequences. This is because of the sequencing machinery, and makes the data "compositional". You must normalize this data to avoid generating artefacts. there is *extensive* literature on this topic. here we will use 2 methods: rarefaction, a classic approach necessary for some analysis models, and cumulative sum scaling with MetagenomeSeq. 

#### 1.4a Rarefaction & rarefying
This method will cut your library sizes to the minimum library size of your sequencing effort, and then repopulate the OTU tables by picking OTUs/ASVs at random. This method effectively trows away a lot of data, so it's coming into disuse.

Still, we will use rarefied data for alpha diversity, neutral model fits, and core microiome definition

```{r}
# let's first adjust some factors
sample_data(physeq_filtered)$Sample_type <- as.factor(sample_data(physeq_filtered)$Sample_type)
sample_data(physeq_clean)$Sample_type <- as.factor(sample_data(physeq_clean)$Sample_type)

# draw rarefaction curve
# here we want to find a plateau: despite increase in the number of DNA reads, we do not increase the number of observed species. essentially, sequencing was deep enought to saturate your sampling effort.
physeq_filtered_df <- as.data.frame(otu_table(physeq_filtered))
rarecurve(t(physeq_filtered_df),
  col = sample_data(physeq_filtered)$Sample_type,
  label = FALSE,
  step = 200,
  main = "Rarefaction at 8678 reads, 8+ occurences, 4898 of 4943 taxa retained", ylab = "Number of ASVs", xlab = "Number of DNA Sequences",
  abline(v = min(sample_sums(physeq_filtered)), col = "red", lwd = 3, lty = 2)
)

# the rarefraction curve is actually quite ok! we won't lose much ASV diversity if we cut at the minimal depth. of course, this is after all the filtering, which removed most rare species

# now, let's rarefy the data
set.seed(100) # set a random seed so that whenever you re-run this code you draw the same set of OTUs
min(sample_sums(physeq_filtered)) # minumum library size
sort.default(colSums(otu_table(physeq_filtered))) # sometimes you might want to lose/remove one or more samples that have a very low library size. you would have to ballance the number of samples with the minimum number of sequences. in this particular dataset, we won't cut any samples as the rarefaction curve looks very good

# runt he rarefaction. with 1 argument per line it becomes easier to see what is going on. naming the arguments also help a lot!
physeq_filtered_rarefied <- rarefy_even_depth(
  physeq = physeq_filtered,
  sample.size = min(sample_sums(physeq_filtered)),
  rngseed = FALSE,
  replace = TRUE,
  trimOTUs = TRUE,
  verbose = TRUE
)


# this will remove any ASVs with 0 reads accidentally put in place
otu_table(physeq_filtered_rarefied) <- otu_table(physeq_filtered_rarefied)[which(rowSums(otu_table(physeq_filtered_rarefied)) >= 1), ]

# at this point all your samples should have an identical library size
colSums(otu_table(physeq_filtered_rarefied))

# check if any taxa has no reads (row completetly full of zeros)
any(taxa_sums(physeq_filtered_rarefied) == 0)

# this will show how much of our sequencing still makes part of our phyloseq object
sum(otu_table(physeq_filtered_rarefied)) / sum(otu_table(physeq_filtered))

# this is your final phyloseq object
physeq_filtered_rarefied

# results of rarefraction: no ASV lost, no samples lost. this is because we used a high filtering (option 1.3c), rarefaction curve achieved a plateau, and minimal library size was not too low.

# assign meja treatment as a factor
sample_data(physeq_filtered_rarefied)$MeJA_treatment <- as.factor(sample_data(physeq_filtered_rarefied)$MeJA_treatment)

# splits rarefied phyloseq object into several lists
pslist_sp_rarefied <- phyloseq_sep_variable(physeq_filtered_rarefied, variable = "Plant_species")
# one list of 2 phyloseq objects for root/soil samples
pslist_root_soil_rarefied <- phyloseq_sep_variable(physeq_filtered_rarefied, variable = "Sample_type")
# one list of 4 phyloseq objects for sample type + species
ps_list_rarefied <- phyloseq_sep_variable(physeq_filtered_rarefied, variable = c("Plant_species", "Sample_type"))

##### *** THIS DATA IS NOW READY FOR ANALYSIS *** ##########

gc() # garbage collection
```
 
#### 1.4b Metagenomseq
We use this package to be able to normalize library sizes without using rarefaction and also accounting for sparsity (high number of zeros in the dataset). This is done by considering the counts up to a certain quantile (comulative sum scaling, CSS). We will perform this with the  metagenomseq package.

We will use CSS-normalized data for beta diversity analysis: ordinations, permanovas and beta dispersion
```{r}
# first, let's transform the phyloseq object into an MR experiment object
MRexp_objt <- phyloseq_to_metagenomeSeq(physeq_filtered)

# normalizes the object by cumulative sum scaling, a widely used method
cumNorm(MRexp_objt)

# here you can acess the abundance matrix normalized by cumulative sum scaling. you could overwrite the phyloseq object with this
CSS_matrix <- MRcounts(MRexp_objt, norm = TRUE, log = TRUE) # using a log scale will essentially reduce the impact of common species and increase the impact of rare species

# make a new phyloseq object...
physeq_filtered_CSS <- physeq_filtered

# and now change it's taxa table
otu_table(physeq_filtered_CSS) <- otu_table(CSS_matrix, taxa_are_rows = TRUE)

# this is your final phyloseq object
physeq_filtered_CSS



# assign meja treatment as a factor
sample_data(physeq_filtered_CSS)$MeJA_treatment <- as.factor(sample_data(physeq_filtered_CSS)$MeJA_treatment)


# creating lists of phyloseq objects
# one list of 2 for B.ole and A.tha
pslist_sp_CSS <- phyloseq_sep_variable(physeq_filtered_CSS, variable = "Plant_species")
# one list of 2 phyloseq objects for root/soil samples
pslist_root_soil_CSS <- phyloseq_sep_variable(physeq_filtered_CSS, variable = "Sample_type")
# one list of 4 phyloseq objects for sample type + species
ps_list_CSS <- phyloseq_sep_variable(physeq_filtered_CSS, variable = c("Plant_species", "Sample_type"))


###########################

gc() # garbage collection
```

#### 1.4c list of different normalization options

```{r}

# now that we have multiple ways of looking at our data, let's make a list of different normalization options
normalization_listed <- list(physeq_filtered_CSS, physeq_filtered_rarefied, physeq_filtered)


names(normalization_listed) <- c(
  "physeq_filtered_CSS",
  "physeq_filtered_rarefied",
  "physeq_filtered"
)
# this is a list of 3 phyloseq objects, each with a different normalization approach
normalization_listed
```

# 1.5 - Data ready for analysis! proceed to scrip 2_Beta_Diversity!

[MA]: Save individual phyloseq or phyloseq lists as R objects so they are easier to use in future scripts.
```{r}

saveRDS(normalization_listed,
        "./R output/01_phyloseq_objects/normalization_listed.rds") #list with CSS, rarefied and non-rarefied
saveRDS(physeq_filtered_rarefied,
        "./R output/01_phyloseq_objects/physeq_filtered_rarefied.rds") #full rarefied
saveRDS(physeq_filtered,
        "./R output/01_phyloseq_objects/physeq_filtered.rds") #full non-rarefied
saveRDS(physeq_filtered_CSS,
        "./R output/01_phyloseq_objects/physeq_filtered_CSS.rds") #full CSS-normalized
saveRDS(ps_list_nonraref,
        "./R output/01_phyloseq_objects/ps_list_nonraref.rds") #non rarefied split by Sp and Root (4)
saveRDS(ps_list_rarefied,
        "./R output/01_phyloseq_objects/ps_list_rarefied.rds") #rarefied split by Sp and Root (4)

#save all just in case 
save.image("./R output/env.1_Loading_and_pre_processing.RData")

```
